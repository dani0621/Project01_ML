# Machine Learning & AI Project 1: NBA Statistics Predictor
## Danielle Li<br />September 26th, 2024
<div align="center">
  <img width="450" alt="nbaLogo" src="https://github.com/user-attachments/assets/b8f8f7e4-6c06-4a98-8756-197dc989c57e">
</div>

### Literature Review/ Resources
I conducted my project on NBA statistics. There were many datasets on Kaggle and the internet in general due to the league's popularity, leading me to find this dataset: [NBA Traditional Boxscores 1997-2024](https://www.kaggle.com/datasets/szymonjwiak/nba-traditional?select=team_traditional.csv). This dataset recorded each NBA game starting in the 1997 season to the 2024 season with the points scored, win/loss (represented by 1 and 0, respectively), blocks, assists, field goals, etc. The multitude of statistics that was recorded made it favorable, and from looking at the data present, I decided that I wanted to create a NBA statistic predictor for not just points but also blocks, assists, rebounds, etc. as there was enough data in CSV to hopefully create accurate predictions. I have consistently watched the NBA in the past couple of years, so I thought it would be fun to do the project on it. In the end, I chose the Kaggle dataset linked earlier for my dataset.

I then looked into existing NBA predictors, which led me to this paper: [Predicting the Outcome of NBA Games](https://digitalcommons.bryant.edu/cgi/viewcontent.cgi?article=1000&context=honors_data_science#:~:text=The%20most%20common%20features%20used,rating%2C%20and%20true%20shooting%20percentage.), which was Matthew Houde's Senior Honors Project for his data science class. Within his paper, he looked at several existing models to see if he could improve the efficacy of the models. He ran six different models (Logistic Regression, Random Forest Classifier, K Neighbors Classifier, Support Vector Classifier, Gaussian Naïve Bayes, and XGBoost Classifieron) in his testing set to see which was the most accurate in its predictions. The results came out to be that the Gaussian Naïve Bayes was the best predictor followed by the Logistic Regression. His research also discussed that Logistic Regression was a common model for predicting sports outcomes. The Linear Regression model was the more plausible choice for my NBA Predictor model as I only had a month and very little machine learning background knowledge to complete this project. This led me to watch these YouTube videos: [Python Machine Learning Tutorial (Data Science)](https://www.youtube.com/watch?v=7eh4d6sabA0) and [Machine Learning Tutorial Python - 3: Linear Regression Multiple Variables](https://www.youtube.com/watch?v=J_LnPL3Qg70), which did provide sample code for my Linear Regression model later on. These two videos explained the basics of how Machine Learning works as well as how it can be implemented within Python. The first video goes through step by step how one would write code if they were to run a Python machine learning model, while the second explains the logic behind multiple variables for a Linear Regression. Houde's work also cited a highly efficient NBA predictor made by Jake Kandell called [NBA Predict](https://github.com/JakeKandell/NBA-Predict/blob/master/createModel.py) who used a Linear Regression model for his prediction model, which can calculate the winning percentage of a game between two NBA teams.

A Linear Regression model finds the relationship between a dependent variable and multiple independent variables by creating a linear equation for the data. The equation, essentially, is going to look similar to a linear equation, y=mx+b, except this time, due to the multiple variables, our equation is y = b + m<sub>1</sub>x<sub>1</sub> + m<sub>2</sub>x<sub>2</sub> + ... + m<sub>n</sub>x<sub>n</sub> (different slopes/coefficients for each independent variable which adds up to the value of the dependent variable). For my project, I had wanted to use a model that would intake multiple variables in order to predict the chose statistic. The popularity of the Linear Regression Model, along with it's ability to predict multiple independent variables for its predictions, led to it being chosen as my ML approach.

I also want to note that ChatGPT and Gemini were both used to debug my code during this process (the exact lines are commented in my code), and ChatGPT was also used to write a few functions that had originally caused bugs in my code. I will go in-depth later on about how the two AIs were used.

### Linear Regression Models
Importing Data: I chose to use Colab because it was the service I used when I first learned about machine learning. It was also beneficial that I didn't have to download PyCharm/other services in order to run my code. I started by importing my libraries, which I looked at from the YouTube videos and Jake Kandell's project. There were also library imports for data evaluation, like NumPy, PANDAS, and math. The libraries I imported from the other sources were from scikit-learn, which contained tools for machine learning and statistical modeling. I also imported files and drive from google.colab in order to connect my Google Drive account to my Colab. I had previously downloaded the dattaset off Kaggle, which I uploaded to my Google Drive. Connecting my Google Drive and Colab allowed me to import my data into my Jupyter Notebook.
<div align="center">
  <img width="400" alt="imports" src="https://github.com/user-attachments/assets/ae63a1d2-284a-43ac-b650-e9faabfaa63e">
</div>


Cleaning the data: I then cleaned my data to preprocess it by deleting the rows that were missing any values and any duplicates. I also created a new dataset with only the games from the 2018-2019 season and onward, as data from an older period would create a model that was more generalized in its predictions. Data beyond five years will start becoming less useful for predictions as the data couldn't reflect current trends. After the seasons before 2019 were taken out, I also created two more variables that I added to the dataset as columns: win percentage and turnover percentage. I obtained the win percentage formula from ChatGPT as the traditional win percentage calculation required a point differential, a statistic I didn't have access to. The turnover percentage formula was found through a quick Google search, and I created the appropriate function in order to add the statistics of that column to my dataset. Once we had added our new variables, we created a new dataset that only contained the columns/variables we needed for our Linear Algorithms so that the dataset only contained the necessary statistics (dropped unnecessary statistics like game ID, type of game, team ID, etc.).

Split data into Train/Test Sets: Before we create our models for each statistic, we need to split our data into training and testing sets. The training set is used to train the model where the model creates the equation with coefficients for the independent variables in the end. This equation is then used against the testing set (with the actual values), where the accuracy of the prediction is evaluated. I decided to split 0.25/0.75 so that 1/4 of my data was used for testing while 3/4 was used for training. We do so for each dependent variable we try to predict.

Creating the model: I used the Linear Regression model to predict multiple game statistics like Points, Rebounds, Turnovers, Assists, Free Throws Made, Blocks, and Field Goals Made. For each of them, I used different independent variables to predict their statistic because only certain statistics have strong associations with the statistics. For example, for the Linear Regression model for predicting the points a team made in a match, I used win percentage, rebounds, turnovers, turnover percent, and number of free throws made along with eight other statistics as the independent variables in order to predict the number of points. I defined the features/independent variables for each linear regression model and then trained the model:
<div align="center">
  <img width="400" alt="imports" src=https://github.com/user-attachments/assets/944ed5cb-b93d-4ba0-9f54-5a7d10eaf573>
</div>

Evaluated Model: After training my model, I evaluated the accuracy of my model's predictions through the Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared. The first three of these evaluations were shown in Jake Kandell's model, which inspired me to use them as a way of calculating accuracy. This was done using the metrics function from sklearn. For MAE, MSE, and RMSE, we want the values to be close to 0 as it would show that there was little to no difference between the predicted values and the actual values. For R-squared, we want the value to be close to 1 as it'd show that the regression predictions fit the data exactly. I also adjusted the size of the test set and the independent variables involved for each linear regression model to obtain the <sup>r2</sup> value closest to 1.

Making Predictions: The predict_game_performance function takes the user's input of (home team, away team, date, season) to predict the outcome of a game with its statistics. It extracts the game data of that day's matchup and then uses the Linear Regression models to predict the different statistics. I also created a function to convert the user's input of the teams' abbreviated names to their full names. Now, the final print message displays the full team names of who would have scored more points during the match, as well as the stats for the home team and the accuracy of the linear regression models. For:
<div align="center">
  <img width="400" alt="imports" src=https://github.com/user-attachments/assets/c8c56faa-be59-401e-aa0c-0ee0110935e4>
</div>
We predicted the following:
<div align="center">
  <img width="800" alt="imports" src=https://github.com/user-attachments/assets/9b48b6bd-4867-407d-84da-dde986da1225>
</div>


### Results/ Problems
When we run our model, it displays the r<sup>2</sup> values, which shows the accuracy of our model. We can see that our predictions for points, rebounds, and field goals are extremely accurate as their r<sup>2</sup> values were 0.961263, 1.00000, and 0.993272, respectively. However, for the other statistics, they all had rather low r<sup>2</sup> values, below 0.5.

Overall, our biggest problem was the lack of statistics available to use to train the dataset. The data set includes the points of our home team and rebounds, locks, etc., but certain points differential and the attempts of the teams to score in general would have been more significant indicators for our data. Defense/offense rating, the win percentage, attempts to shoot, and attempts at rebounds, from the NBA's main statistics, would have been vital for the prediction of certain independent variables. However, since we lacked the variables/statistics, I had to use alternate variables as our dataset. For turnovers, for example, this is heavily influenced by the opponents' defensive pressure, and since we didn't calculate the opponents' defense statistic into the model, this would have led us to not be able to create predictions as accurately (leading to the low r<sup>2</sup> value). This continued to be true for the other linear regressions as well


For assists, we didn't have the opponent's defense factor into the model and individual trends for assists, leading to a less than 0.5 r<sup>2</sup> value. For blocks, they are dependent on the opponent's shooting percentage in general or for their field goal, but we didn't have that statistic available, so our blocks' linear regression model is dependent on the home team's number of rebounds and steals. Though these two factors could help in making the predictive model, they are not factors that make the most impact and are not amazing indiciators of the number of blocks (lowest r<sup>2</sup> value of 0.04478). Free throws also had a low  <sup>2</sup> value where we lacked statistics on the opponents' foul rate as well as a rating for how aggressive the players were, which meant that points, field goal attempts, and rebounds, aren't the best inindependentairblesfor our model to train on for our free throe linear regression model. The problems I ran into were all about the availability and acessability of data where statistics like point differential and win percentage were hard to extract. This led me to train the model on alternate independent variables that aren't the best indicators of the statistic (led to very low r<sup>2</sup> values). Having other statistics like offensive/defensive efficacy would have also allowed me to predict the win probability of a team, which I attempted to calculate in the beginning, but doing so with just basic statistics isn't possible with my dataset, even with the incorporation of formulas. I then used the independent variables that were the best predictors available in my dataset. I also changed these variables around for each model in order to obtain the R-squared value closest to one.

The other problem i ran into was the formatting of the date that was inputted. Oriiginally, the game couldn't be found even though it existed,so I had asked chatGPT for a solution in order to make sure that the game date awas always found. THe other problem I ran into was on my part where I didn'correctly access certain functions or used columns that were out of the functions' scope, which didn't allow me to access my models as the columns were mismatched. 

#### Future Work
The data that I previously mentioned that I didn't have accesss to could be precurred as this would heavily increase the accuracy of mour model. If I had more time I could have also split the data into home team and away team in the beginning and thn created the linear regression models for each dataset so that we could obtain the opponent's statistics too. The more statistics that I have would also with the predictive modeling of the defensive statistics. Personal data preference could also be found in order to see the pace set for the game along with the agressiveness. With more time, I think a more complex and accurate game report would be given as we are able to obtain the data for the independnet variables that are more idnicative of the dependent vairables for my linear regression models. If new data could be obtained along with time, a complex win probability equaito would also be written in roder to predict the win percentage for our teams (a different statistic I could predict).
