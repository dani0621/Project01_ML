# Machine Learning & AI Project 1: NBA Statistics Predictor
## Danielle Li<br />September 26th, 2024
<div align="center">
  <img width="450" alt="nbaLogo" src="https://github.com/user-attachments/assets/b8f8f7e4-6c06-4a98-8756-197dc989c57e">
</div>

### Literature Review/ Resources
I conducted my project on NBA statistics. There were many datasets on Kaggle and the internet in general due to the league's popularity, leading me to find this dataset: [NBA Traditional Boxscores 1997-2024](https://www.kaggle.com/datasets/szymonjwiak/nba-traditional?select=team_traditional.csv). This dataset recorded each NBA game starting in the 1997 season to the 2024 season with the points scored, win/loss (represented by 1 and 0, respectively), blocks, assists, field goals, etc. The multitude of statistics that was recorded made it favorable, and from looking at the data present, I decided that I wanted to create a NBA statistic predictor for not just points but also blocks, assists, rebounds, etc. as there was enough data in the csv to hopefully create accurate predictions. I have consistently watched the NBA in the past couple of years, so I thought it would be fun to do the project on it. In the end, I chose the Kaggle dataset linked earlier for my dataset.

I then looked into existing NBA predictors, which led me to this paper: [Predicting the Outcome of NBA Games](https://digitalcommons.bryant.edu/cgi/viewcontent.cgi?article=1000&context=honors_data_science#:~:text=The%20most%20common%20features%20used,rating%2C%20and%20true%20shooting%20percentage.), which was Matthew Houde's Senior Honors Project for his data science class. Within his paper, he looked at several existing models to see if he could improve the efficacy of the models. He ran six different models (Logistic Regression, Random Forest Classifier, K Neighbors Classifier, Support Vector Classifier, Gaussian Naïve Bayes, and XGBoost Classifieron) in his testing set to see which was the most accurate in its predictions. The results came out to be that the Gaussian Naïve Bayes was the best predictor followed by the Logistic Regression. His research also discussed that Logistic Regression was a common model for predicting sports outcomes. I looked into it more and decided that a Linear Regression model was a more plausible choice for my NBA Predictor model as I only had a month and very little machine learning background knowledge to complete this project. This led me to watch these YouTube videos: [Python Machine Learning Tutorial (Data Science)](https://www.youtube.com/watch?v=7eh4d6sabA0) and [Machine Learning Tutorial Python - 3: Linear Regression Multiple Variables](https://www.youtube.com/watch?v=J_LnPL3Qg70), which did provide sample code for my Linear Regression model later on. These two videos explained the basics of how Machine Learning works as well as how it can be implemented within Python. The first video goes through step by step how one would write code if they were to run a Python machine learning model, while the second explains the logic behind multiple variables for a Linear Regression. Houde's work also cited a highly efficient NBA predictor made by Jake Kandell called [NBA Predict](https://github.com/JakeKandell/NBA-Predict/blob/master/createModel.py) who used a Linear Regression model for his prediction model, which can calculate the winning percentage of a game between two NBA teams.

A Linear Regression model finds the relationship between a dependent variable and multiple independent variables by creating a linear equation for the data. The equation, essentially, is going to look similar to a linear equation, y=mx+b, except this time, due to the multiple variables, our equation is y = b + m<sub>1</sub>x<sub>1</sub> + m<sub>2</sub>x<sub>2</sub> + ... + m<sub>n</sub>x<sub>n</sub> (different slopes/coefficients for each independent variable which adds up to the value of the dependent variable). For my project, I had wanted to use a model that would intake multiple variables in order to predict the chose statistic. The popularity of the Linear Regression Model, along with it's ability to predict multiple independent variables for its predictions, led to it being chosen as my ML approach.

I also want to note that ChatGPT and Gemini were both used to debug my code during this process (the exact lines are commented in my code), and ChatGPT was also used to write a few functions that had originally caused bugs in my code. I will go in-depth later on about how the two AIs were used.

### Linear Regression Models
Importing Data: I chose to use Colab because it was the service I used when I first learned about machine learning. It was also beneficial that I didn't have to download PyCharm/other services in order to run my code. I started by importing my libraries, which I looked at from the YouTube videos and Jake Kandell's project. There were also library imports for data evaluation, like NumPy, PANDAS, and math. The libraries I imported from the other sources were from scikit-learn, which contained tools for machine learning and statistical modeling. I also imported files and drive from google.colab in order to connect my Google Drive account to my Colab. I had previously downloaded the dattaset off Kaggle, which I uploaded to my Google Drive. Connecting my Google Drive and Colab allowed me to import my data into my Jupyter Notebook.
<div align="center">
  <img width="400" alt="imports" src="https://github.com/user-attachments/assets/ae63a1d2-284a-43ac-b650-e9faabfaa63e">
</div>


Cleaning the data: I then cleaned my data to preprocess it by deleting the rows that were missing any values and any duplicates. I also created a new dataset with only the games from the 2018-2019 season and onward, as data from an older period would create a model that was more generalized in its predictions. Data beyond five years will start becoming less useful for predictions as the data couldn't reflect current trends. After the seasons before 2019 were taken out, I also created two more variables that I added to the dataset as columns: win percentage and turnover percentage. I obtained the win percentage formula from ChatGPT as the traditional win percentage calculation required a point differential, a statistic I didn't have access to. The turnover percentage formula was found through a quick Google search, and I created the appropriate function in order to add the statistics of that column to my dataset. Once we had added our new variables, we created a new dataset that only contained the columns/variables we needed for our Linear Algorithms so that the dataset only contained the necessary statistics (dropped unnecessary statistics like game ID, type of game, team ID, etc.).

Split data into Train/Test Sets: Before we create our models for each statistic, we need to split our data into training and testing sets. The training set is used to train the model where the model creates the equation with coefficients for the independent variables in the end. This equation is then used against the testing set (with the actual values), where the accuracy of the prediction is evaluated. I decided to split 0.25/0.75 so that 1/4 of my data was used for testing while 3/4 was used for training. We do so for each dependent variable we try to predict.

Creating the model: I used the Linear Regression model to predict multiple game statistics like Points, Rebounds, Turnovers, Assists, Free Throws Made, Blocks, and Field Goals Made. For each of them, I used different independent variables to predict their statistic because only certain statistics have strong associations with the statistics. For example, for the Linear Regression model for predicting the points a team made in a match, I used win percentage, rebounds, turnovers, turnover percent, and number of free throws made along with eight other statistics as the independent variables in order to predict the number of points. I then defined the features/independent variables for each linear regression model and then trained the model:
<div align="center">
  <img width="400" alt="imports" src=https://github.com/user-attachments/assets/944ed5cb-b93d-4ba0-9f54-5a7d10eaf573>
</div>

Evaluated Model: After training my model, I evaluated the accuracy of my model's predictions through the Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared. The first three of these evaluations were shown in Jake Kandell's model, which inspired me to use them as a way of calculating accuracy. This was done using the metrics function from sklearn. For MAE, MSE, and RMSE, we want the values to be close to 0 as it would show that there was little to no difference between the predicted values and the actual values. For R-squared, we want the value to be close to 1 as it'd show that the regression predictions fit the data exactly. I also adjusted the size of the test set and the independent variables involved for each linear regression model to obtain the r<sup>2</sup> value closest to 1.

Making Predictions: The predict_game_performance function takes the user's input of (home team, away team, date, season) to predict the outcome of a game with its statistics. It extracts the game data of that day's matchup and then uses the Linear Regression models to predict the different statistics. I also created a function to convert the user's input of the teams' abbreviated names to their full names. Now, the final print message displays the full team names of who would have scored more points during the match, as well as the stats for the home team and the accuracy of the linear regression models. For:
<div align="center">
  <img width="400" alt="imports" src=https://github.com/user-attachments/assets/c8c56faa-be59-401e-aa0c-0ee0110935e4>
</div>
We predicted the following:
<div align="center">
  <img width="800" alt="imports" src=https://github.com/user-attachments/assets/9b48b6bd-4867-407d-84da-dde986da1225>
</div>


### Results/ Problems
When we run our model, it displays the r<sup>2</sup> values, which shows the accuracy of our model. We can see that our predictions for points, rebounds, and field goals are extremely accurate as their r<sup>2</sup> values were 0.961263, 1.00000, and 0.993272, respectively. This makes sense because we have the strongest predictors for these statistics available in our data. However, for the other statistics, they all had rather low r<sup>2</sup> values, below 0.5. This will be explained later on in more detail, but we can associate the rather low r<sup>2</sup> values due to these statistics' not having the optimal variables. The optimal variables like defense/offense rating and win percentage require statistics that are not easily accessible, meaning that instead of using those variables, we are using the best alternatives (determined by test and trial and evaluating the r<sup>2</sup> values). However, the accuracy of these alternative variables don't have a strong correlation, meaning that their ability to accutately predict the statistics isn't very high, leading to the low r<sup>2</sup> values.

Overall, our biggest problem was the lack of statistics available to use to train the dataset. The data set includes the points of our home team and rebounds, locks, etc., but certain points differential and the attempts of the teams to score in general would have been more significant indicators for our data. Defense/offense rating, the win percentage, attempts to shoot, and attempts at rebounds, from the NBA's main statistics, would have been vital for the prediction of certain independent variables. However, since we lacked the variables/statistics, I had to use alternate variables as our dataset. Turnovers, for example, are heavily influenced by the opponents' defensive pressure, and since we didn't calculate the opponents' defense statistic into the model, this would have led us to not be able to create predictions as accurately (leading to the low r<sup>2</sup> value). This continued to be true for the other linear regressions as well where statistics that were heavily influenced by the opponents' defense, such as assists and and free throws. For these statistics, I had to use alternate factors that were available in my data set, so these factors were not amazing indicators but were the best I had.

Another problem I ran into was about the availability and acessability of data where statistics like point differential and win percentage were hard to extract from stats.nba.com. I had originally wanted to calculate the win percentage as well, but with the lack of offense/defense rating and point potential, any linear regression predictions wouldn't have been accurate. This led me to train the model on alternate independent variables that aren't the best indicators of the statistic (led to very low r<sup>2</sup> values). Having other statistics like offensive/defensive efficacy would have also allowed me to predict the win probability of a team, which I attempted to calculate in the beginning but doing so with just basic statistics isn't possible with my dataset, even with the incorporation of formulas. I then had to use the independent variables that were the best predictors available in my dataset. I concluded which variables to use for each model by comparing the R-squared values and choosing the ones that produced a r<sup>2</sup> value closest to one.

The other problem I ran into was the formatting of the date from the user's input. Originally, when the user inputted a date, the model couldn't find that matchup on the day even though the game did exist (checked manuually). I even printed out game_date, which was correct and matched the dataset. I asked ChatGPT for a solution in order to make sure that the game date was always found. The other problem I ran into was on my part where I didn't correctly access the parameters for my model, so they were out of the functions' scope and didn't allow me to access my models as the columns were mismatched. 

#### Future Work
In the future, I could procure the data that I previously mentioned, which would be difficult to obtain from stats. nba.com, as that would increase the accuracy of our model. I could have also split the data into home team and away team datasets in the beginning and then created the linear regression models for each dataset so that we could obtain the opponent's statistics. Having the opponents' statistics would allow me to create functions abot the opponents' defense, which would increase the accuracy of certain statistics like rebounds, steals, etc. With more time, I think a more complex and accurate game report would be given as we can obtain the data for the independent variables that are more indicative of the dependent variables for my linear regression models. If new data could be obtained along with time, a complex win probability equation would also be written in order to predict the win percentage for our teams (a different statistic that I could predict).
